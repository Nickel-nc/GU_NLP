{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Import libs\n",
    "##############\n",
    "\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !reload(sys).setdefaultencoding(\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n"
     ]
    }
   ],
   "source": [
    "print(sys.stdout.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Settings\n",
    "###########\n",
    "\n",
    "INPUT_FILE = \"data/Otvety.txt\"\n",
    "OUTPUT_FILE = 'output/prepared_answers.txt'\n",
    "SENTENCE_LIMIT = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "\n",
      "вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО ВАМ здесь кого советовали завести?)) . \n",
      "\n",
      "хомячка.... \n",
      "\n",
      "мужика, йопаря, собачку и 50 кошек))). \n",
      "\n",
      "Общение !). \n",
      "\n",
      "паучка. \n",
      "\n",
      "Да пол мне бы памыть!<br>А таг то ни чо. Типа ни каво!. \n",
      "\n",
      "я тут вообще что бы пообщаться..... \n",
      "\n",
      "А мне советовали сиси завести...))). \n",
      "\n",
      "Ну, слава богу, мужика завести ещё не советовали))) А вот сватать к кому только не сватали). \n",
      "\n",
      "мне тут советовали завести любовника, мужа и много кошек )))<br>приветик ))). \n",
      "\n",
      "---\n",
      "\n",
      "Как парни относятся к цветным линзам? Если у девушки то зеленые глаза, то голубые...)) . \n",
      "\n",
      "меня вобще прикалывает эта тема :). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text Overview\n",
    "\n",
    "with open(\"data/Otvety.txt\", \"r\", encoding='utf-8') as f:\n",
    "    line_gen = [next(f) for x in range(15)]\n",
    "    for line in line_gen:\n",
    "        print(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Modules\n",
    "###############\n",
    "\n",
    "\n",
    "def extract_answers(input_file,\n",
    "                    output_file\n",
    "                   ):\n",
    "\n",
    "    \"\"\"Extracts and write answers to distinct file\"\"\"\n",
    "    \n",
    "    question = None\n",
    "    written = False\n",
    "\n",
    "    with open(input_file, \"w\", encoding='utf-8') as fout:\n",
    "\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as fin:\n",
    "\n",
    "            for line in tqdm(fin): \n",
    "                \n",
    "                # 1-st line after '---' == question\n",
    "                # lines to '---' == answers\n",
    "\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue\n",
    "    \n",
    "    \n",
    "    \n",
    "def preprocess_txt(line):\n",
    "    \n",
    "    \"\"\"Light text preprocessing and morpher \"\"\"\n",
    "    \n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls\n",
    "\n",
    "\n",
    "def get_sentences(input_file, len_limit=100000):\n",
    "    \n",
    "    \"\"\"Process text. extract sentense tokens with morph processor\"\"\"\n",
    "    \n",
    "    # Preprocess for models fitting\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    c = 0\n",
    "\n",
    "    with open(input_file, \"r\", encoding='utf-8') as fin:\n",
    "        for line in tqdm(fin):\n",
    "            spls = preprocess_txt(line)\n",
    "            sentences.append(spls)\n",
    "            c += 1\n",
    "            if c > len_limit:\n",
    "                break\n",
    "                \n",
    "    return sentences\n",
    "\n",
    "\n",
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(50)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7550926it [00:20, 375319.06it/s]\n"
     ]
    }
   ],
   "source": [
    "assert False  #  Set True if not exists\n",
    "\n",
    "extract_answers(INPUT_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sentences(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['научно',\n",
       " 'производственный',\n",
       " 'предприятие',\n",
       " 'итэлмавыпускать',\n",
       " 'счётчик',\n",
       " 'электроника',\n",
       " 'немецкий',\n",
       " 'технология']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, size=50, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=sentences, size=50, min_count=1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bcbcfb21cb4aa494539bcab5581f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "496it [00:21, 160.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(50 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(50 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(OUTPUT_FILE, \"r\", encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_w2v = np.zeros(50)\n",
    "        vector_ft = np.zeros(50)\n",
    "        for word in question:\n",
    "            if word in modelW2V:\n",
    "                vector_w2v += modelW2V[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT:\n",
    "                vector_ft += modelFT[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 100000:\n",
    "            break\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1093, 1122, 2186]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index.get_nns_by_vector(np.zeros(50), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(50)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Когда нейроны в нервной системе протаптывают тропинки?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p> Соматическая нервная система подчинена воле человека, т.е. захотел сел, захотел руку поднял. Она регулирует работу скелетных мышц, ее центры находятся в коре больших полушарий(КБП). </p>. \\n',\n",
       " 'не останавливайтесь на полпути.. .<br>. \\n',\n",
       " 'Нет не повредит. Только приведёт в порядок файловую систему, при это ничего не удаляется. Если это конечно, Акронис, а не палёная троянская версия :))). \\n']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, modelW2V, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['несовершенного <br>делать - делающий. \\n',\n",
       " 'где? в мозгу... \\n',\n",
       " 'не останавливайтесь на полпути.. .<br>. \\n']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, modelFT, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "w2v_index.save('output/w2v_idx')\n",
    "ft_index.save('output/ft_idx')\n",
    "\n",
    "with open('output/index_map.pkl', 'wb') as f:\n",
    "    pickle.dump(index_map, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
