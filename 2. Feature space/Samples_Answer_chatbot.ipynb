{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Import libs\n",
    "##############\n",
    "\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.stdout.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Settings\n",
    "###########\n",
    "\n",
    "INPUT_FILE = \"data/Otvety.txt\"\n",
    "OUTPUT_FILE = 'output/prepared_answers.txt'\n",
    "SENTENCE_LIMIT = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "\n",
      "вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО ВАМ здесь кого советовали завести?)) . \n",
      "\n",
      "хомячка.... \n",
      "\n",
      "мужика, йопаря, собачку и 50 кошек))). \n",
      "\n",
      "Общение !). \n",
      "\n",
      "паучка. \n",
      "\n",
      "Да пол мне бы памыть!<br>А таг то ни чо. Типа ни каво!. \n",
      "\n",
      "я тут вообще что бы пообщаться..... \n",
      "\n",
      "А мне советовали сиси завести...))). \n",
      "\n",
      "Ну, слава богу, мужика завести ещё не советовали))) А вот сватать к кому только не сватали). \n",
      "\n",
      "мне тут советовали завести любовника, мужа и много кошек )))<br>приветик ))). \n",
      "\n",
      "---\n",
      "\n",
      "Как парни относятся к цветным линзам? Если у девушки то зеленые глаза, то голубые...)) . \n",
      "\n",
      "\n",
      "меня вобще прикалывает эта тема :). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text Overview\n",
    "\n",
    "with open(\"data/Otvety.txt\", \"r\", encoding='utf-8') as f:\n",
    "    line_gen = [next(f) for x in range(15)]\n",
    "    for line in line_gen:\n",
    "        print(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Modules\n",
    "###############\n",
    "\n",
    "\n",
    "def extract_answers(input_file,\n",
    "                    output_file\n",
    "                   ):\n",
    "\n",
    "    \"\"\"Extracts and write answers to distinct file\"\"\"\n",
    "    \n",
    "    question = None\n",
    "    written = False\n",
    "\n",
    "    with open(input_file, \"w\", encoding='utf-8') as fout:\n",
    "\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as fin:\n",
    "\n",
    "            for line in tqdm(fin): \n",
    "                \n",
    "                # 1-st line after '---' == question\n",
    "                # lines to '---' == answers\n",
    "\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue\n",
    "    \n",
    "    \n",
    "    \n",
    "def preprocess_txt(line, exclude=exclude, morpher=morpher, sw=sw):\n",
    "    \n",
    "    \"\"\"Light text preprocessing and morpher \"\"\"\n",
    "    \n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls\n",
    "\n",
    "\n",
    "def get_sentences(input_file, len_limit=100000):\n",
    "    \n",
    "    \"\"\"Process text. extract sentense tokens with morph processor\"\"\"\n",
    "    \n",
    "    # Preprocess for models fitting\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    c = 0\n",
    "\n",
    "    with open(input_file, \"r\", encoding='utf-8') as fin:\n",
    "        for line in tqdm(fin):\n",
    "            spls = preprocess_txt(line, exclude, morpher, sw)\n",
    "            sentences.append(spls)\n",
    "            c += 1\n",
    "            if c > len_limit:\n",
    "                break\n",
    "                \n",
    "    return sentences, exclude, morpher, sw\n",
    "\n",
    "\n",
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(50)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9565bf3bcd87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m#  Set True to prepare data if not exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mextract_answers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False  #  Set True to prepare data if not exists\n",
    "\n",
    "extract_answers(INPUT_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b53d341a5d44bf924c59f97bb52548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences, exclude, morpher, sw = get_sentences(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['научно',\n",
       " 'производственный',\n",
       " 'предприятие',\n",
       " 'итэлмавыпускать',\n",
       " 'счётчик',\n",
       " 'электроника',\n",
       " 'немецкий',\n",
       " 'технология']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, size=50, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=sentences, size=50, min_count=1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2f51a895a84f27ab9e8ed1a5c9447e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(50 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(50 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(OUTPUT_FILE, \"r\", encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_w2v = np.zeros(50)\n",
    "        vector_ft = np.zeros(50)\n",
    "        for word in question:\n",
    "            if word in modelW2V:\n",
    "                vector_w2v += modelW2V[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT:\n",
    "                vector_ft += modelFT[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > SENTENCE_LIMIT:\n",
    "            break\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4052, 7949, 12846]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index.get_nns_by_vector(np.zeros(50), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(50)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Когда нейроны в нервной системе протаптывают тропинки?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p> Соматическая нервная система подчинена воле человека, т.е. захотел сел, захотел руку поднял. Она регулирует работу скелетных мышц, ее центры находятся в коре больших полушарий(КБП). </p>. \\n',\n",
       " 'Только не рабы, а продукты.. \\n',\n",
       " 'Нет не повредит. Только приведёт в порядок файловую систему, при это ничего не удаляется. Если это конечно, Акронис, а не палёная троянская версия :))). \\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, modelW2V, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['где? в мозгу... \\n',\n",
       " 'http://bikes.ironhorse.ru/archives/36. \\n',\n",
       " 'раньше мечтали о свечном заводике, а теперь о нефтяных вышках... разузнайте почту владельца нефтяной вышки и обсудите с ним варианты купли-продажи. или дайте объявления на все возможные телевизионные каналы. (особое внимание РБК) Выгоднее будет построить нефтеперерабатывающий завод - быстрее окупится.. \\n']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, modelFT, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "w2v_index.save('output/w2v_idx')\n",
    "ft_index.save('output/ft_idx')\n",
    "\n",
    "with open('output/index_map.pkl', 'wb') as f:\n",
    "    pickle.dump(index_map, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
