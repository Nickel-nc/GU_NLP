{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import dialogflow\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import regex as re\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "from data.keyvault import keyvault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Settings\n",
    "###########\n",
    "\n",
    "DATA_PATH = \"data/Otvety.txt\"\n",
    "ANSWERS_PATH = 'data/prepared_answers.txt'\n",
    "FASTTEXT_MODEL_PATH = 'data/ft_100_model.h5'\n",
    "RAW_SENTENCES_PATH = 'data/raw_sentences.pkl'\n",
    "INDEX_MAP_PATH = 'data/index_map.pkl'\n",
    "FT_INDEX_PATH = 'data/ft_index'\n",
    "FT_VECTOR_MAX_LEN = 100\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рутина предобработки. Подготовка и обучение FastText модели на ответах mail.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(input_file, len_limit=1500000):\n",
    "    \n",
    "    \"\"\"Process text. extract sentense tokens with morph processor\"\"\"\n",
    "    \n",
    "    # Preprocess for models fitting\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    c = 0\n",
    "\n",
    "    with open(input_file, \"r\", encoding='utf-8') as fin:\n",
    "        for line in tqdm(fin):\n",
    "            spls = preprocess_txt(line, exclude, morpher, sw)\n",
    "            sentences.append(spls)\n",
    "            c += 1\n",
    "            if c > len_limit:\n",
    "                break\n",
    "                \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37372ec564cd420a982adccdb26d50ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = get_sentences(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(FASTTEXT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0599f43cac904f6f9be769edec014c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# modelFT = FastText.load(\"ft_model.h5\")\n",
    "\n",
    "# Создание индексов FastText\n",
    "ft_index = annoy.AnnoyIndex(FT_VECTOR_MAX_LEN ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(ANSWERS_PATH, \"r\", encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        vector_ft = np.zeros(FT_VECTOR_MAX_LEN)\n",
    "        for word in question:\n",
    "            if word in modelFT:\n",
    "                vector_ft += modelFT[word]\n",
    "                n_ft += 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "# Сохранение просчитанной карты индексов\n",
    "with open(INDEX_MAP_PATH, 'wb') as f:\n",
    "    pickle.dump(index_map, f)\n",
    "    \n",
    "# Построеиние индексов на 20 деревьях и сохранение на диск\n",
    "ft_index.build(20)\n",
    "ft_index.save(FT_INDEX_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация функционала. Загрузка и тестирование бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка заготовок: Fast text модель, индексы, индексированная карта ответов\n",
    "\n",
    "modelFT = FastText.load(FASTTEXT_MODEL_PATH)\n",
    "\n",
    "ft_index = annoy.AnnoyIndex(FT_VECTOR_MAX_LEN, 'angular')\n",
    "ft_index.load(FT_INDEX_PATH)\n",
    "\n",
    "with open(INDEX_MAP_PATH, 'rb') as f:\n",
    "    index_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    \"\"\"Строковый препроцессинг,  текстовой строки строки\"\"\"\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls\n",
    "\n",
    "def get_response(question, index, model, index_map):\n",
    "#     print(f'question is: {question}')\n",
    "    \n",
    "    \"\"\"Получение ответа из модели fast text\"\"\"\n",
    "    \n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(FT_VECTOR_MAX_LEN)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 5) \n",
    "    return [index_map[i] for i in answers if len(index_map[i]) < 300] # \n",
    "\n",
    "\n",
    "def web_search_answer(question:str) -> str:\n",
    "    # position = 'Data scientist'\n",
    "    query = question\n",
    "    main_link = 'https://yandex.ru/search/'\n",
    "    link = main_link + f\"?text={query.replace(' ', '%20')}&lr=213\"\n",
    "    try:\n",
    "        req = requests.get(f'{link}').text\n",
    "        parsed_html = bs(req, 'html.parser')\n",
    "        target_block = parsed_html.find('div',{'class':'fact-answer'})\n",
    "        res = target_block.contents[0]\n",
    "    except:\n",
    "        res = None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['в \"кое-где\", а \"кое-где\" \"где-то там\", которая находится \"он туды\", а это \"он туды\" \"он там\", а \"он там\" \"у чёрта на куличиках\".. \\n',\n",
       " 'рай?. \\n',\n",
       " 'Напрашивается слово в пиз...а так судя по растениям юго-запад северной америки. \\n']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тестирование модуля болталки на \"ответах mail.ru\"\n",
    "input_text = \"Где мы находимся?\" #   \"когда выйдет халф лайф 3?\"\n",
    "r = get_response(input_text, ft_index, modelFT, index_map)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_sent(text):\n",
    "    \n",
    "    \"\"\"Очистка текста от тегов, обработка лишних знаков препинаний, смайлов и прочего мусора\"\"\"\n",
    "    \n",
    "    target_sent = random.choice(text)\n",
    "    target_sent = re.sub(r'<[^>]*>','', target_sent)\n",
    "    target_sent = re.sub(r'[\\xa0]',' ', target_sent)\n",
    "    target_sent = re.sub(r'.{1,2} [\\n]','', target_sent)\n",
    "    target_sent = re.sub(r'[\\n]','', target_sent)\n",
    "    target_sent = re.sub(r'\\s[.]\\s','', target_sent)\n",
    "    target_sent = re.sub(r\"\\)\\)\\)\\)\", \"))\", target_sent)\n",
    "    target_sent = re.sub(r\"\\)\\)\", \")\", target_sent)\n",
    "    target_sent = re.sub(r\"\\) \\)\", \"))\", target_sent)\n",
    "    target_sent = re.sub(r',{2,}','', target_sent)\n",
    "    return target_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в \"кое-где\", а \"кое-где\" \"где-то там\", которая находится \"он туды\", а это \"он туды\" \"он там\", а \"он там\" \"у чёрта на куличиках\"'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_sent(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: TelegramDeprecationWarning: Old Handler API is deprecated - see https://git.io/fxJuV for details\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "updater = Updater(token=keyvault['telegram_token'])\n",
    "dispatcher = updater.dispatcher\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = keyvault['google_api_key'] # Ключ к google API dialogflow\n",
    "\n",
    "DIALOGFLOW_PROJECT_ID = keyvault['dialogflow_project_id'] # PROJECT ID DialogFlow \n",
    "DIALOGFLOW_LANGUAGE_CODE = 'ru' # языковая группа\n",
    "SESSION_ID = 'SetMyTasksBot'  # ID телеграмм бота\n",
    "\n",
    "start_msg = 'R1D1 машет клешнёй! Бот может поддержать беседу веселой болтовнёй и отвечать на глупые вопросы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startCommand(bot, update):\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=start_msg)\n",
    "    logging.info(\"Start Bot\")\n",
    "\n",
    "def textMessage(bot, update):\n",
    "    \n",
    "    # Начало: Поиск интентов на DialogFlow\n",
    "    input_txt = update.message.text\n",
    "    print(f\"input_txt is: {input_txt}\")\n",
    "    session_client = dialogflow.SessionsClient()\n",
    "    session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "    text_input = dialogflow.types.TextInput(text=input_txt, language_code=DIALOGFLOW_LANGUAGE_CODE)\n",
    "    query_input = dialogflow.types.QueryInput(text=text_input)\n",
    "    \n",
    "    try:\n",
    "        response = session_client.detect_intent(session=session, query_input=query_input)\n",
    "    except InvalidArgument:\n",
    "         raise\n",
    "\n",
    "    text = response.query_result.fulfillment_text\n",
    "    if text and text != 'null':\n",
    "        response = response.query_result.fulfillment_text\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=response)\n",
    "    else:\n",
    "        response = web_search_answer(input_txt)\n",
    "        if response != None:\n",
    "            bot.send_message(chat_id=update.message.chat_id, text=response)\n",
    "        else:\n",
    "        # Интент DialogFlow на найден --> включение режима болталки на \"ответах mail.ru\"\n",
    "            response = get_response(input_txt, ft_index, modelFT, index_map)\n",
    "            response = clear_sent(response)\n",
    "            bot.send_message(chat_id=update.message.chat_id, text=response)\n",
    "    print(f\"Response is: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_txt is: Привет\n",
      "Response is: И тебе не хворать\n",
      "input_txt is: Как дела на марсе?\n",
      "Response is: У меня лучшая в мире работа - в чате косить под бота!\n",
      "input_txt is: Ты кто?\n",
      "Response is: Я великий Бендер!\n",
      "input_txt is: кто создал таблицу Менделеева?\n",
      "Response is: Дмитрий Иванович Менделеев\n",
      "input_txt is: когда выйдет халф лайф 3?\n",
      "Response is: Последняя игра во франшизе \n",
      "input_txt is: Что у тебя в голове, бот?\n",
      "Response is: Да. И горжусь этим!\n",
      "input_txt is: Ты бот?\n",
      "Response is: Да. И горжусь этим!\n",
      "input_txt is: косил косой косой косой?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response is: После кислотных дождей-испуг вороны-удобрение))\n"
     ]
    }
   ],
   "source": [
    "# Хендлеры\n",
    "\n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "# Добавляем хендлеры в диспатчер\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "# Начинаем поиск обновлений\n",
    "updater.start_polling(clean=True)\n",
    "# Останавливаем бота на Ctrl + C\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
