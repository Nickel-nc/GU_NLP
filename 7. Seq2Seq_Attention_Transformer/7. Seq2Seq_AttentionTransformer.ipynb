{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запустить seq2seq, seq2seq с внимаием и \n",
    "# трансформер для перевода русских слов \n",
    "# + описать наблюдения по качеству Данные в папке data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n",
      "Hi.\tSalut !\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\n",
      "Hi.\tSalut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\n",
      "Run!\tCours !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\n",
      "Run!\tCourez !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\n",
      "Who?\tQui ?\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4366796 (gillux)\n",
      "Wow!\tÇa alors !\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #374631 (zmoo)\n",
      "Fire!\tAu feu !\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #4627939 (sacredceltic)\n",
      "Help!\tÀ l'aide !\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #128430 (sysko)\n",
      "Jump.\tSaute.\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #2416938 (Micsmithel)\n",
      "Stop!\tÇa suffit !\tCC-BY 2.0 (France) Attribution: t\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read()[:1000]\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем one-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 1.3364 - accuracy: 0.7207 - val_loss: 1.0798 - val_accuracy: 0.7007\n",
      "Epoch 2/30\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.8893 - accuracy: 0.7542 - val_loss: 0.9226 - val_accuracy: 0.7557\n",
      "Epoch 3/30\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.7503 - accuracy: 0.7959 - val_loss: 0.7792 - val_accuracy: 0.7805\n",
      "Epoch 4/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.6439 - accuracy: 0.8183 - val_loss: 0.6991 - val_accuracy: 0.7986\n",
      "Epoch 5/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.6448 - accuracy: 0.8204 - val_loss: 0.7728 - val_accuracy: 0.7791\n",
      "Epoch 6/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.5987 - accuracy: 0.8279 - val_loss: 0.6569 - val_accuracy: 0.8098\n",
      "Epoch 7/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.5575 - accuracy: 0.8378 - val_loss: 0.6307 - val_accuracy: 0.8148\n",
      "Epoch 8/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5365 - accuracy: 0.8429 - val_loss: 0.6152 - val_accuracy: 0.8183\n",
      "Epoch 9/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5206 - accuracy: 0.8471 - val_loss: 0.5972 - val_accuracy: 0.8245\n",
      "Epoch 10/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5059 - accuracy: 0.8514 - val_loss: 0.5835 - val_accuracy: 0.8285\n",
      "Epoch 11/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4935 - accuracy: 0.8546 - val_loss: 0.5716 - val_accuracy: 0.8311\n",
      "Epoch 12/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4809 - accuracy: 0.8575 - val_loss: 0.5617 - val_accuracy: 0.8342\n",
      "Epoch 13/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4696 - accuracy: 0.8608 - val_loss: 0.5508 - val_accuracy: 0.8363\n",
      "Epoch 14/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4586 - accuracy: 0.8637 - val_loss: 0.5408 - val_accuracy: 0.8396\n",
      "Epoch 15/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4492 - accuracy: 0.8664 - val_loss: 0.5343 - val_accuracy: 0.8418\n",
      "Epoch 16/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4392 - accuracy: 0.8693 - val_loss: 0.5239 - val_accuracy: 0.8437\n",
      "Epoch 17/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4295 - accuracy: 0.8716 - val_loss: 0.5186 - val_accuracy: 0.8454\n",
      "Epoch 18/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4206 - accuracy: 0.8747 - val_loss: 0.5075 - val_accuracy: 0.8499\n",
      "Epoch 19/30\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4111 - accuracy: 0.8775 - val_loss: 0.5040 - val_accuracy: 0.8496\n",
      "Epoch 20/30\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.4021 - accuracy: 0.8798 - val_loss: 0.5061 - val_accuracy: 0.8482\n",
      "Epoch 21/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3951 - accuracy: 0.8814 - val_loss: 0.4921 - val_accuracy: 0.8539\n",
      "Epoch 22/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3861 - accuracy: 0.8846 - val_loss: 0.4871 - val_accuracy: 0.8558\n",
      "Epoch 23/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3773 - accuracy: 0.8868 - val_loss: 0.4799 - val_accuracy: 0.8576\n",
      "Epoch 24/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3688 - accuracy: 0.8894 - val_loss: 0.4724 - val_accuracy: 0.8599\n",
      "Epoch 25/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3602 - accuracy: 0.8917 - val_loss: 0.4698 - val_accuracy: 0.8606\n",
      "Epoch 26/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3527 - accuracy: 0.8940 - val_loss: 0.4671 - val_accuracy: 0.8630\n",
      "Epoch 27/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3448 - accuracy: 0.8963 - val_loss: 0.4572 - val_accuracy: 0.8648\n",
      "Epoch 28/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3381 - accuracy: 0.8985 - val_loss: 0.4591 - val_accuracy: 0.8649\n",
      "Epoch 29/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3304 - accuracy: 0.9006 - val_loss: 0.4602 - val_accuracy: 0.8649\n",
      "Epoch 30/30\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3230 - accuracy: 0.9028 - val_loss: 0.4502 - val_accuracy: 0.8679\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: La vie-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Comment-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Comment-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Laisse-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Laisse-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Qui vous a trait ?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Les chammeste tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: La vie le tourde !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Bonn !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Dépête-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrêtez-le !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrêtez-le !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrêtez-le !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attends-le.\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attends-le.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Bonn un chache !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Bonn un chache !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je l'ai conté.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Je l'ai reculé.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je vous ai cheure.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je vous ai cheure.\n",
      "\n",
      "-\n",
      "Input sentence: I won.\n",
      "Decoded sentence: Je veux de le cheux.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: On mon !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Laisse-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Laisse-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Laisse-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Laisse-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Avez la chante !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Avez la chante !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pass-il ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pass-il ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pass-il ?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Comment !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Comment !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Dide-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Dide-moi !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis sentie trais de le mier.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis sentie trais de le mier.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je suis de le moir.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis de le mien.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis de le mien.\n",
      "\n",
      "-\n",
      "Input sentence: I lied.\n",
      "Decoded sentence: J'ai décher.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai en chance.\n",
      "\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: Je l'ai saisé.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Je suis détentille.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis de la mais.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis de la mais.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Restez alle !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Sarde-moi ?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Sarde-moi ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Sarde-moi ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merti les chantes.\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: Nous sommes en train de train de le mair.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous ne vous ons pas des ller.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous ne vous ons pas des ller.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous ne vous ons pas des ller.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous ne vous ons pas des ller.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Le vois es comme.\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: À plus !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Soyez contentis !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Soyez concelle !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Viens !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "data_path = 'data/fra-eng/fra.txt'\n",
    "num_samples = 10000\n",
    "\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.6143\n",
      "Epoch 2 Loss 1.1783\n",
      "Epoch 3 Loss 0.9852\n",
      "Epoch 4 Loss 0.8354\n",
      "Epoch 5 Loss 0.7105\n",
      "Epoch 6 Loss 0.6048\n",
      "Epoch 7 Loss 0.5088\n",
      "Epoch 8 Loss 0.4286\n",
      "Epoch 9 Loss 0.3576\n",
      "Epoch 10 Loss 0.2966\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nickel\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'char']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> good morning <end>\n",
      "Predicted translation: d p che toi . <end> \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c62fe7b3b252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pylab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'good morning'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-61331b77bd12>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted translation: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mattention_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mplot_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-61331b77bd12>\u001b[0m in \u001b[0;36mplot_attention\u001b[1;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "translate(u'good morning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.2410 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.1235 Accuracy 0.0026\n",
      "Epoch 1 Batch 100 Loss 7.8938 Accuracy 0.0329\n",
      "Epoch 1 Loss 7.8018 Accuracy 0.0394\n",
      "Epoch 2 Batch 0 Loss 7.3054 Accuracy 0.0667\n",
      "Epoch 2 Batch 50 Loss 7.1507 Accuracy 0.0668\n",
      "Epoch 2 Batch 100 Loss 6.9214 Accuracy 0.0761\n",
      "Epoch 2 Loss 6.7941 Accuracy 0.0855\n",
      "Epoch 3 Batch 0 Loss 6.1125 Accuracy 0.1302\n",
      "Epoch 3 Batch 50 Loss 5.8124 Accuracy 0.1301\n",
      "Epoch 3 Batch 100 Loss 5.5447 Accuracy 0.1305\n",
      "Epoch 3 Loss 5.4207 Accuracy 0.1305\n",
      "Epoch 4 Batch 0 Loss 4.7127 Accuracy 0.1281\n",
      "Epoch 4 Batch 50 Loss 4.5637 Accuracy 0.1362\n",
      "Epoch 4 Batch 100 Loss 4.3927 Accuracy 0.1460\n",
      "Epoch 4 Loss 4.3274 Accuracy 0.1494\n",
      "Epoch 5 Batch 0 Loss 3.9715 Accuracy 0.1594\n",
      "Epoch 5 Batch 50 Loss 3.8074 Accuracy 0.1695\n",
      "Epoch 5 Batch 100 Loss 3.6903 Accuracy 0.1747\n",
      "Epoch 5 Loss 3.6448 Accuracy 0.1767\n",
      "Epoch 6 Batch 0 Loss 3.4187 Accuracy 0.1885\n",
      "Epoch 6 Batch 50 Loss 3.3176 Accuracy 0.1899\n",
      "Epoch 6 Batch 100 Loss 3.2512 Accuracy 0.1925\n",
      "Epoch 6 Loss 3.2247 Accuracy 0.1936\n",
      "Epoch 7 Batch 0 Loss 3.0877 Accuracy 0.1979\n",
      "Epoch 7 Batch 50 Loss 3.0014 Accuracy 0.2032\n",
      "Epoch 7 Batch 100 Loss 2.9571 Accuracy 0.2043\n",
      "Epoch 7 Loss 2.9450 Accuracy 0.2047\n",
      "Epoch 8 Batch 0 Loss 2.8424 Accuracy 0.2135\n",
      "Epoch 8 Batch 50 Loss 2.7483 Accuracy 0.2135\n",
      "Epoch 8 Batch 100 Loss 2.7325 Accuracy 0.2147\n",
      "Epoch 8 Loss 2.7222 Accuracy 0.2146\n",
      "Epoch 9 Batch 0 Loss 2.5560 Accuracy 0.2219\n",
      "Epoch 9 Batch 50 Loss 2.5283 Accuracy 0.2235\n",
      "Epoch 9 Batch 100 Loss 2.5285 Accuracy 0.2226\n",
      "Epoch 9 Loss 2.5251 Accuracy 0.2229\n",
      "Epoch 10 Batch 0 Loss 2.4545 Accuracy 0.2292\n",
      "Epoch 10 Batch 50 Loss 2.3785 Accuracy 0.2291\n",
      "Epoch 10 Batch 100 Loss 2.3535 Accuracy 0.2290\n",
      "Epoch 10 Loss 2.3474 Accuracy 0.2292\n",
      "Epoch 11 Batch 0 Loss 2.4015 Accuracy 0.2229\n",
      "Epoch 11 Batch 50 Loss 2.2053 Accuracy 0.2344\n",
      "Epoch 11 Batch 100 Loss 2.1817 Accuracy 0.2349\n",
      "Epoch 11 Loss 2.1835 Accuracy 0.2348\n",
      "Epoch 12 Batch 0 Loss 2.0171 Accuracy 0.2479\n",
      "Epoch 12 Batch 50 Loss 2.0298 Accuracy 0.2402\n",
      "Epoch 12 Batch 100 Loss 2.0189 Accuracy 0.2421\n",
      "Epoch 12 Loss 2.0218 Accuracy 0.2417\n",
      "Epoch 13 Batch 0 Loss 1.7969 Accuracy 0.2438\n",
      "Epoch 13 Batch 50 Loss 1.9024 Accuracy 0.2473\n",
      "Epoch 13 Batch 100 Loss 1.8884 Accuracy 0.2474\n",
      "Epoch 13 Loss 1.8849 Accuracy 0.2481\n",
      "Epoch 14 Batch 0 Loss 1.7259 Accuracy 0.2625\n",
      "Epoch 14 Batch 50 Loss 1.7511 Accuracy 0.2548\n",
      "Epoch 14 Batch 100 Loss 1.7401 Accuracy 0.2550\n",
      "Epoch 14 Loss 1.7457 Accuracy 0.2540\n",
      "Epoch 15 Batch 0 Loss 1.6178 Accuracy 0.2656\n",
      "Epoch 15 Batch 50 Loss 1.5800 Accuracy 0.2632\n",
      "Epoch 15 Batch 100 Loss 1.6034 Accuracy 0.2611\n",
      "Epoch 15 Loss 1.6065 Accuracy 0.2609\n",
      "Epoch 16 Batch 0 Loss 1.4397 Accuracy 0.2781\n",
      "Epoch 16 Batch 50 Loss 1.4665 Accuracy 0.2676\n",
      "Epoch 16 Batch 100 Loss 1.4812 Accuracy 0.2664\n",
      "Epoch 16 Loss 1.4867 Accuracy 0.2665\n",
      "Epoch 17 Batch 0 Loss 1.3029 Accuracy 0.2677\n",
      "Epoch 17 Batch 50 Loss 1.3629 Accuracy 0.2721\n",
      "Epoch 17 Batch 100 Loss 1.3637 Accuracy 0.2739\n",
      "Epoch 17 Loss 1.3634 Accuracy 0.2736\n",
      "Epoch 18 Batch 0 Loss 1.2941 Accuracy 0.2646\n",
      "Epoch 18 Batch 50 Loss 1.2280 Accuracy 0.2808\n",
      "Epoch 18 Batch 100 Loss 1.2535 Accuracy 0.2787\n",
      "Epoch 18 Loss 1.2592 Accuracy 0.2785\n",
      "Epoch 19 Batch 0 Loss 1.0958 Accuracy 0.2865\n",
      "Epoch 19 Batch 50 Loss 1.1104 Accuracy 0.2896\n",
      "Epoch 19 Batch 100 Loss 1.1452 Accuracy 0.2863\n",
      "Epoch 19 Loss 1.1593 Accuracy 0.2853\n",
      "Epoch 20 Batch 0 Loss 0.9981 Accuracy 0.2958\n",
      "Epoch 20 Batch 50 Loss 1.0263 Accuracy 0.2947\n",
      "Epoch 20 Batch 100 Loss 1.0615 Accuracy 0.2902\n",
      "Epoch 20 Loss 1.0730 Accuracy 0.2898\n",
      "Epoch 21 Batch 0 Loss 0.9397 Accuracy 0.3104\n",
      "Epoch 21 Batch 50 Loss 0.9607 Accuracy 0.2990\n",
      "Epoch 21 Batch 100 Loss 0.9745 Accuracy 0.2963\n",
      "Epoch 21 Loss 0.9837 Accuracy 0.2956\n",
      "Epoch 22 Batch 0 Loss 0.8896 Accuracy 0.3073\n",
      "Epoch 22 Batch 50 Loss 0.8557 Accuracy 0.3057\n",
      "Epoch 22 Batch 100 Loss 0.8853 Accuracy 0.3018\n",
      "Epoch 22 Loss 0.9024 Accuracy 0.3002\n",
      "Epoch 23 Batch 0 Loss 0.7865 Accuracy 0.3208\n",
      "Epoch 23 Batch 50 Loss 0.7996 Accuracy 0.3084\n",
      "Epoch 23 Batch 100 Loss 0.8364 Accuracy 0.3049\n",
      "Epoch 23 Loss 0.8491 Accuracy 0.3034\n",
      "Epoch 24 Batch 0 Loss 0.7272 Accuracy 0.3052\n",
      "Epoch 24 Batch 50 Loss 0.7221 Accuracy 0.3140\n",
      "Epoch 24 Batch 100 Loss 0.7710 Accuracy 0.3092\n",
      "Epoch 24 Loss 0.7831 Accuracy 0.3080\n",
      "Epoch 25 Batch 0 Loss 0.5768 Accuracy 0.3375\n",
      "Epoch 25 Batch 50 Loss 0.6855 Accuracy 0.3190\n",
      "Epoch 25 Batch 100 Loss 0.7216 Accuracy 0.3134\n",
      "Epoch 25 Loss 0.7437 Accuracy 0.3108\n",
      "Epoch 26 Batch 0 Loss 0.6358 Accuracy 0.3063\n",
      "Epoch 26 Batch 50 Loss 0.6483 Accuracy 0.3184\n",
      "Epoch 26 Batch 100 Loss 0.6858 Accuracy 0.3154\n",
      "Epoch 26 Loss 0.6999 Accuracy 0.3139\n",
      "Epoch 27 Batch 0 Loss 0.5877 Accuracy 0.3271\n",
      "Epoch 27 Batch 50 Loss 0.6118 Accuracy 0.3240\n",
      "Epoch 27 Batch 100 Loss 0.6443 Accuracy 0.3192\n",
      "Epoch 27 Loss 0.6603 Accuracy 0.3172\n",
      "Epoch 28 Batch 0 Loss 0.5547 Accuracy 0.3094\n",
      "Epoch 28 Batch 50 Loss 0.5694 Accuracy 0.3274\n",
      "Epoch 28 Batch 100 Loss 0.6149 Accuracy 0.3216\n",
      "Epoch 28 Loss 0.6334 Accuracy 0.3192\n",
      "Epoch 29 Batch 0 Loss 0.4664 Accuracy 0.3417\n",
      "Epoch 29 Batch 50 Loss 0.5523 Accuracy 0.3253\n",
      "Epoch 29 Batch 100 Loss 0.5903 Accuracy 0.3224\n",
      "Epoch 29 Loss 0.6047 Accuracy 0.3216\n",
      "Epoch 30 Batch 0 Loss 0.5169 Accuracy 0.3406\n",
      "Epoch 30 Batch 50 Loss 0.5407 Accuracy 0.3266\n",
      "Epoch 30 Batch 100 Loss 0.5678 Accuracy 0.3244\n",
      "Epoch 30 Loss 0.5828 Accuracy 0.3231\n",
      "Epoch 31 Batch 0 Loss 0.5442 Accuracy 0.3354\n",
      "Epoch 31 Batch 50 Loss 0.5180 Accuracy 0.3311\n",
      "Epoch 31 Batch 100 Loss 0.5523 Accuracy 0.3267\n",
      "Epoch 31 Loss 0.5720 Accuracy 0.3243\n",
      "Epoch 32 Batch 0 Loss 0.4380 Accuracy 0.3344\n",
      "Epoch 32 Batch 50 Loss 0.5051 Accuracy 0.3291\n",
      "Epoch 32 Batch 100 Loss 0.5442 Accuracy 0.3265\n",
      "Epoch 32 Loss 0.5629 Accuracy 0.3247\n",
      "Epoch 33 Batch 0 Loss 0.4153 Accuracy 0.3333\n",
      "Epoch 33 Batch 50 Loss 0.4827 Accuracy 0.3318\n",
      "Epoch 33 Batch 100 Loss 0.5190 Accuracy 0.3288\n",
      "Epoch 33 Loss 0.5367 Accuracy 0.3270\n",
      "Epoch 34 Batch 0 Loss 0.4330 Accuracy 0.3146\n",
      "Epoch 34 Batch 50 Loss 0.4694 Accuracy 0.3328\n",
      "Epoch 34 Batch 100 Loss 0.5023 Accuracy 0.3304\n",
      "Epoch 34 Loss 0.5176 Accuracy 0.3286\n",
      "Epoch 35 Batch 0 Loss 0.3871 Accuracy 0.3396\n",
      "Epoch 35 Batch 50 Loss 0.4363 Accuracy 0.3372\n",
      "Epoch 35 Batch 100 Loss 0.4749 Accuracy 0.3334\n",
      "Epoch 35 Loss 0.4908 Accuracy 0.3318\n",
      "Epoch 36 Batch 0 Loss 0.3652 Accuracy 0.3479\n",
      "Epoch 36 Batch 50 Loss 0.4226 Accuracy 0.3390\n",
      "Epoch 36 Batch 100 Loss 0.4585 Accuracy 0.3342\n",
      "Epoch 36 Loss 0.4732 Accuracy 0.3327\n",
      "Epoch 37 Batch 0 Loss 0.3856 Accuracy 0.3458\n",
      "Epoch 37 Batch 50 Loss 0.4119 Accuracy 0.3398\n",
      "Epoch 37 Batch 100 Loss 0.4502 Accuracy 0.3362\n",
      "Epoch 37 Loss 0.4607 Accuracy 0.3344\n",
      "Epoch 38 Batch 0 Loss 0.4095 Accuracy 0.3323\n",
      "Epoch 38 Batch 50 Loss 0.3888 Accuracy 0.3440\n",
      "Epoch 38 Batch 100 Loss 0.4324 Accuracy 0.3381\n",
      "Epoch 38 Loss 0.4436 Accuracy 0.3361\n",
      "Epoch 39 Batch 0 Loss 0.3819 Accuracy 0.3427\n",
      "Epoch 39 Batch 50 Loss 0.3712 Accuracy 0.3463\n",
      "Epoch 39 Batch 100 Loss 0.4058 Accuracy 0.3402\n",
      "Epoch 39 Loss 0.4230 Accuracy 0.3385\n",
      "Epoch 40 Batch 0 Loss 0.3578 Accuracy 0.3396\n",
      "Epoch 40 Batch 50 Loss 0.3732 Accuracy 0.3433\n",
      "Epoch 40 Batch 100 Loss 0.4062 Accuracy 0.3396\n",
      "Epoch 40 Loss 0.4171 Accuracy 0.3386\n",
      "Epoch 41 Batch 0 Loss 0.3344 Accuracy 0.3490\n",
      "Epoch 41 Batch 50 Loss 0.3469 Accuracy 0.3471\n",
      "Epoch 41 Batch 100 Loss 0.3811 Accuracy 0.3431\n",
      "Epoch 41 Loss 0.3972 Accuracy 0.3412\n",
      "Epoch 42 Batch 0 Loss 0.3104 Accuracy 0.3562\n",
      "Epoch 42 Batch 50 Loss 0.3490 Accuracy 0.3468\n",
      "Epoch 42 Batch 100 Loss 0.3728 Accuracy 0.3432\n",
      "Epoch 42 Loss 0.3869 Accuracy 0.3414\n",
      "Epoch 43 Batch 0 Loss 0.2655 Accuracy 0.3562\n",
      "Epoch 43 Batch 50 Loss 0.3311 Accuracy 0.3490\n",
      "Epoch 43 Batch 100 Loss 0.3666 Accuracy 0.3434\n",
      "Epoch 43 Loss 0.3823 Accuracy 0.3420\n",
      "Epoch 44 Batch 0 Loss 0.2819 Accuracy 0.3688\n",
      "Epoch 44 Batch 50 Loss 0.3312 Accuracy 0.3499\n",
      "Epoch 44 Batch 100 Loss 0.3637 Accuracy 0.3440\n",
      "Epoch 44 Loss 0.3742 Accuracy 0.3425\n",
      "Epoch 45 Batch 0 Loss 0.3127 Accuracy 0.3573\n",
      "Epoch 45 Batch 50 Loss 0.3315 Accuracy 0.3454\n",
      "Epoch 45 Batch 100 Loss 0.3543 Accuracy 0.3446\n",
      "Epoch 45 Loss 0.3687 Accuracy 0.3435\n",
      "Epoch 46 Batch 0 Loss 0.3435 Accuracy 0.3417\n",
      "Epoch 46 Batch 50 Loss 0.3114 Accuracy 0.3483\n",
      "Epoch 46 Batch 100 Loss 0.3430 Accuracy 0.3461\n",
      "Epoch 46 Loss 0.3552 Accuracy 0.3451\n",
      "Epoch 47 Batch 0 Loss 0.2956 Accuracy 0.3531\n",
      "Epoch 47 Batch 50 Loss 0.3097 Accuracy 0.3486\n",
      "Epoch 47 Batch 100 Loss 0.3409 Accuracy 0.3455\n",
      "Epoch 47 Loss 0.3504 Accuracy 0.3452\n",
      "Epoch 48 Batch 0 Loss 0.3148 Accuracy 0.3583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 50 Loss 0.2921 Accuracy 0.3545\n",
      "Epoch 48 Batch 100 Loss 0.3300 Accuracy 0.3471\n",
      "Epoch 48 Loss 0.3414 Accuracy 0.3459\n",
      "Epoch 49 Batch 0 Loss 0.2741 Accuracy 0.3635\n",
      "Epoch 49 Batch 50 Loss 0.2941 Accuracy 0.3508\n",
      "Epoch 49 Batch 100 Loss 0.3219 Accuracy 0.3483\n",
      "Epoch 49 Loss 0.3353 Accuracy 0.3469\n",
      "Epoch 50 Batch 0 Loss 0.2782 Accuracy 0.3417\n",
      "Epoch 50 Batch 50 Loss 0.2859 Accuracy 0.3503\n",
      "Epoch 50 Batch 100 Loss 0.3178 Accuracy 0.3489\n",
      "Epoch 50 Loss 0.3276 Accuracy 0.3475\n",
      "Epoch 51 Batch 0 Loss 0.3146 Accuracy 0.3396\n",
      "Epoch 51 Batch 50 Loss 0.2890 Accuracy 0.3498\n",
      "Epoch 51 Batch 100 Loss 0.3108 Accuracy 0.3494\n",
      "Epoch 51 Loss 0.3217 Accuracy 0.3483\n",
      "Epoch 52 Batch 0 Loss 0.3071 Accuracy 0.3615\n",
      "Epoch 52 Batch 50 Loss 0.2717 Accuracy 0.3545\n",
      "Epoch 52 Batch 100 Loss 0.3026 Accuracy 0.3503\n",
      "Epoch 52 Loss 0.3155 Accuracy 0.3487\n",
      "Epoch 53 Batch 0 Loss 0.2846 Accuracy 0.3562\n",
      "Epoch 53 Batch 50 Loss 0.2841 Accuracy 0.3511\n",
      "Epoch 53 Batch 100 Loss 0.3013 Accuracy 0.3499\n",
      "Epoch 53 Loss 0.3115 Accuracy 0.3495\n",
      "Epoch 54 Batch 0 Loss 0.1674 Accuracy 0.3646\n",
      "Epoch 54 Batch 50 Loss 0.2725 Accuracy 0.3521\n",
      "Epoch 54 Batch 100 Loss 0.3035 Accuracy 0.3490\n",
      "Epoch 54 Loss 0.3140 Accuracy 0.3484\n",
      "Epoch 55 Batch 0 Loss 0.3353 Accuracy 0.3271\n",
      "Epoch 55 Batch 50 Loss 0.2740 Accuracy 0.3531\n",
      "Epoch 55 Batch 100 Loss 0.2957 Accuracy 0.3508\n",
      "Epoch 55 Loss 0.3057 Accuracy 0.3497\n",
      "Epoch 56 Batch 0 Loss 0.2006 Accuracy 0.3604\n",
      "Epoch 56 Batch 50 Loss 0.2671 Accuracy 0.3537\n",
      "Epoch 56 Batch 100 Loss 0.2888 Accuracy 0.3516\n",
      "Epoch 56 Loss 0.3007 Accuracy 0.3499\n",
      "Epoch 57 Batch 0 Loss 0.2087 Accuracy 0.3698\n",
      "Epoch 57 Batch 50 Loss 0.2513 Accuracy 0.3550\n",
      "Epoch 57 Batch 100 Loss 0.2823 Accuracy 0.3517\n",
      "Epoch 57 Loss 0.2960 Accuracy 0.3507\n",
      "Epoch 58 Batch 0 Loss 0.2027 Accuracy 0.3688\n",
      "Epoch 58 Batch 50 Loss 0.2623 Accuracy 0.3553\n",
      "Epoch 58 Batch 100 Loss 0.2807 Accuracy 0.3520\n",
      "Epoch 58 Loss 0.2900 Accuracy 0.3512\n",
      "Epoch 59 Batch 0 Loss 0.2218 Accuracy 0.3490\n",
      "Epoch 59 Batch 50 Loss 0.2563 Accuracy 0.3562\n",
      "Epoch 59 Batch 100 Loss 0.2758 Accuracy 0.3533\n",
      "Epoch 59 Loss 0.2890 Accuracy 0.3513\n",
      "Epoch 60 Batch 0 Loss 0.2731 Accuracy 0.3490\n",
      "Epoch 60 Batch 50 Loss 0.2493 Accuracy 0.3552\n",
      "Epoch 60 Batch 100 Loss 0.2765 Accuracy 0.3528\n",
      "Epoch 60 Loss 0.2892 Accuracy 0.3513\n",
      "Epoch 61 Batch 0 Loss 0.1984 Accuracy 0.3760\n",
      "Epoch 61 Batch 50 Loss 0.2456 Accuracy 0.3555\n",
      "Epoch 61 Batch 100 Loss 0.2687 Accuracy 0.3538\n",
      "Epoch 61 Loss 0.2796 Accuracy 0.3522\n",
      "Epoch 62 Batch 0 Loss 0.2159 Accuracy 0.3406\n",
      "Epoch 62 Batch 50 Loss 0.2433 Accuracy 0.3551\n",
      "Epoch 62 Batch 100 Loss 0.2710 Accuracy 0.3528\n",
      "Epoch 62 Loss 0.2799 Accuracy 0.3517\n",
      "Epoch 63 Batch 0 Loss 0.1983 Accuracy 0.3521\n",
      "Epoch 63 Batch 50 Loss 0.2451 Accuracy 0.3544\n",
      "Epoch 63 Batch 100 Loss 0.2669 Accuracy 0.3529\n",
      "Epoch 63 Loss 0.2769 Accuracy 0.3523\n",
      "Epoch 64 Batch 0 Loss 0.1963 Accuracy 0.3542\n",
      "Epoch 64 Batch 50 Loss 0.2346 Accuracy 0.3577\n",
      "Epoch 64 Batch 100 Loss 0.2638 Accuracy 0.3543\n",
      "Epoch 64 Loss 0.2738 Accuracy 0.3524\n",
      "Epoch 65 Batch 0 Loss 0.1742 Accuracy 0.3583\n",
      "Epoch 65 Batch 50 Loss 0.2344 Accuracy 0.3567\n",
      "Epoch 65 Batch 100 Loss 0.2561 Accuracy 0.3548\n",
      "Epoch 65 Loss 0.2656 Accuracy 0.3533\n",
      "Epoch 66 Batch 0 Loss 0.2215 Accuracy 0.3625\n",
      "Epoch 66 Batch 50 Loss 0.2343 Accuracy 0.3577\n",
      "Epoch 66 Batch 100 Loss 0.2536 Accuracy 0.3554\n",
      "Epoch 66 Loss 0.2636 Accuracy 0.3537\n",
      "Epoch 67 Batch 0 Loss 0.2085 Accuracy 0.3615\n",
      "Epoch 67 Batch 50 Loss 0.2364 Accuracy 0.3573\n",
      "Epoch 67 Batch 100 Loss 0.2558 Accuracy 0.3538\n",
      "Epoch 67 Loss 0.2666 Accuracy 0.3529\n",
      "Epoch 68 Batch 0 Loss 0.2557 Accuracy 0.3500\n",
      "Epoch 68 Batch 50 Loss 0.2313 Accuracy 0.3557\n",
      "Epoch 68 Batch 100 Loss 0.2517 Accuracy 0.3554\n",
      "Epoch 68 Loss 0.2618 Accuracy 0.3536\n",
      "Epoch 69 Batch 0 Loss 0.1918 Accuracy 0.3667\n",
      "Epoch 69 Batch 50 Loss 0.2261 Accuracy 0.3574\n",
      "Epoch 69 Batch 100 Loss 0.2459 Accuracy 0.3554\n",
      "Epoch 69 Loss 0.2565 Accuracy 0.3546\n",
      "Epoch 70 Batch 0 Loss 0.2542 Accuracy 0.3552\n",
      "Epoch 70 Batch 50 Loss 0.2240 Accuracy 0.3576\n",
      "Epoch 70 Batch 100 Loss 0.2473 Accuracy 0.3547\n",
      "Epoch 70 Loss 0.2571 Accuracy 0.3542\n",
      "Epoch 71 Batch 0 Loss 0.2292 Accuracy 0.3500\n",
      "Epoch 71 Batch 50 Loss 0.2296 Accuracy 0.3563\n",
      "Epoch 71 Batch 100 Loss 0.2465 Accuracy 0.3545\n",
      "Epoch 71 Loss 0.2553 Accuracy 0.3539\n",
      "Epoch 72 Batch 0 Loss 0.1190 Accuracy 0.3688\n",
      "Epoch 72 Batch 50 Loss 0.2198 Accuracy 0.3600\n",
      "Epoch 72 Batch 100 Loss 0.2428 Accuracy 0.3559\n",
      "Epoch 72 Loss 0.2538 Accuracy 0.3546\n",
      "Epoch 73 Batch 0 Loss 0.2113 Accuracy 0.3490\n",
      "Epoch 73 Batch 50 Loss 0.2237 Accuracy 0.3562\n",
      "Epoch 73 Batch 100 Loss 0.2427 Accuracy 0.3554\n",
      "Epoch 73 Loss 0.2506 Accuracy 0.3545\n",
      "Epoch 74 Batch 0 Loss 0.1863 Accuracy 0.3885\n",
      "Epoch 74 Batch 50 Loss 0.2134 Accuracy 0.3600\n",
      "Epoch 74 Batch 100 Loss 0.2381 Accuracy 0.3558\n",
      "Epoch 74 Loss 0.2471 Accuracy 0.3549\n",
      "Epoch 75 Batch 0 Loss 0.1327 Accuracy 0.3771\n",
      "Epoch 75 Batch 50 Loss 0.2176 Accuracy 0.3578\n",
      "Epoch 75 Batch 100 Loss 0.2392 Accuracy 0.3553\n",
      "Epoch 75 Loss 0.2467 Accuracy 0.3547\n",
      "Epoch 76 Batch 0 Loss 0.2384 Accuracy 0.3812\n",
      "Epoch 76 Batch 50 Loss 0.2181 Accuracy 0.3586\n",
      "Epoch 76 Batch 100 Loss 0.2357 Accuracy 0.3569\n",
      "Epoch 76 Loss 0.2436 Accuracy 0.3553\n",
      "Epoch 77 Batch 0 Loss 0.1927 Accuracy 0.3698\n",
      "Epoch 77 Batch 50 Loss 0.2125 Accuracy 0.3582\n",
      "Epoch 77 Batch 100 Loss 0.2373 Accuracy 0.3557\n",
      "Epoch 77 Loss 0.2455 Accuracy 0.3548\n",
      "Epoch 78 Batch 0 Loss 0.1541 Accuracy 0.3865\n",
      "Epoch 78 Batch 50 Loss 0.2076 Accuracy 0.3583\n",
      "Epoch 78 Batch 100 Loss 0.2301 Accuracy 0.3564\n",
      "Epoch 78 Loss 0.2380 Accuracy 0.3559\n",
      "Epoch 79 Batch 0 Loss 0.1925 Accuracy 0.3646\n",
      "Epoch 79 Batch 50 Loss 0.2124 Accuracy 0.3570\n",
      "Epoch 79 Batch 100 Loss 0.2310 Accuracy 0.3561\n",
      "Epoch 79 Loss 0.2408 Accuracy 0.3551\n",
      "Epoch 80 Batch 0 Loss 0.2073 Accuracy 0.3698\n",
      "Epoch 80 Batch 50 Loss 0.2138 Accuracy 0.3588\n",
      "Epoch 80 Batch 100 Loss 0.2328 Accuracy 0.3560\n",
      "Epoch 80 Loss 0.2398 Accuracy 0.3556\n",
      "Epoch 81 Batch 0 Loss 0.2334 Accuracy 0.3531\n",
      "Epoch 81 Batch 50 Loss 0.2063 Accuracy 0.3573\n",
      "Epoch 81 Batch 100 Loss 0.2277 Accuracy 0.3561\n",
      "Epoch 81 Loss 0.2363 Accuracy 0.3556\n",
      "Epoch 82 Batch 0 Loss 0.1949 Accuracy 0.3635\n",
      "Epoch 82 Batch 50 Loss 0.2063 Accuracy 0.3590\n",
      "Epoch 82 Batch 100 Loss 0.2242 Accuracy 0.3570\n",
      "Epoch 82 Loss 0.2346 Accuracy 0.3557\n",
      "Epoch 83 Batch 0 Loss 0.1566 Accuracy 0.3521\n",
      "Epoch 83 Batch 50 Loss 0.2019 Accuracy 0.3587\n",
      "Epoch 83 Batch 100 Loss 0.2240 Accuracy 0.3560\n",
      "Epoch 83 Loss 0.2326 Accuracy 0.3557\n",
      "Epoch 84 Batch 0 Loss 0.1709 Accuracy 0.3677\n",
      "Epoch 84 Batch 50 Loss 0.2036 Accuracy 0.3602\n",
      "Epoch 84 Batch 100 Loss 0.2238 Accuracy 0.3573\n",
      "Epoch 84 Loss 0.2313 Accuracy 0.3565\n",
      "Epoch 85 Batch 0 Loss 0.1582 Accuracy 0.3740\n",
      "Epoch 85 Batch 50 Loss 0.2088 Accuracy 0.3570\n",
      "Epoch 85 Batch 100 Loss 0.2256 Accuracy 0.3564\n",
      "Epoch 85 Loss 0.2314 Accuracy 0.3560\n",
      "Epoch 86 Batch 0 Loss 0.1489 Accuracy 0.3729\n",
      "Epoch 86 Batch 50 Loss 0.2024 Accuracy 0.3579\n",
      "Epoch 86 Batch 100 Loss 0.2208 Accuracy 0.3567\n",
      "Epoch 86 Loss 0.2286 Accuracy 0.3561\n",
      "Epoch 87 Batch 0 Loss 0.2452 Accuracy 0.3490\n",
      "Epoch 87 Batch 50 Loss 0.2002 Accuracy 0.3606\n",
      "Epoch 87 Batch 100 Loss 0.2187 Accuracy 0.3574\n",
      "Epoch 87 Loss 0.2266 Accuracy 0.3562\n",
      "Epoch 88 Batch 0 Loss 0.2236 Accuracy 0.3594\n",
      "Epoch 88 Batch 50 Loss 0.2074 Accuracy 0.3584\n",
      "Epoch 88 Batch 100 Loss 0.2180 Accuracy 0.3574\n",
      "Epoch 88 Loss 0.2237 Accuracy 0.3565\n",
      "Epoch 89 Batch 0 Loss 0.1671 Accuracy 0.3688\n",
      "Epoch 89 Batch 50 Loss 0.2054 Accuracy 0.3579\n",
      "Epoch 89 Batch 100 Loss 0.2196 Accuracy 0.3571\n",
      "Epoch 89 Loss 0.2256 Accuracy 0.3567\n",
      "Epoch 90 Batch 0 Loss 0.1763 Accuracy 0.3375\n",
      "Epoch 90 Batch 50 Loss 0.1997 Accuracy 0.3582\n",
      "Epoch 90 Batch 100 Loss 0.2176 Accuracy 0.3568\n",
      "Epoch 90 Loss 0.2245 Accuracy 0.3562\n",
      "Epoch 91 Batch 0 Loss 0.1875 Accuracy 0.3771\n",
      "Epoch 91 Batch 50 Loss 0.1905 Accuracy 0.3627\n",
      "Epoch 91 Batch 100 Loss 0.2098 Accuracy 0.3588\n",
      "Epoch 91 Loss 0.2196 Accuracy 0.3574\n",
      "Epoch 92 Batch 0 Loss 0.1963 Accuracy 0.3521\n",
      "Epoch 92 Batch 50 Loss 0.1923 Accuracy 0.3596\n",
      "Epoch 92 Batch 100 Loss 0.2116 Accuracy 0.3577\n",
      "Epoch 92 Loss 0.2211 Accuracy 0.3565\n",
      "Epoch 93 Batch 0 Loss 0.1633 Accuracy 0.3698\n",
      "Epoch 93 Batch 50 Loss 0.1959 Accuracy 0.3595\n",
      "Epoch 93 Batch 100 Loss 0.2132 Accuracy 0.3584\n",
      "Epoch 93 Loss 0.2200 Accuracy 0.3571\n",
      "Epoch 94 Batch 0 Loss 0.1564 Accuracy 0.3625\n",
      "Epoch 94 Batch 50 Loss 0.1908 Accuracy 0.3594\n",
      "Epoch 94 Batch 100 Loss 0.2093 Accuracy 0.3577\n",
      "Epoch 94 Loss 0.2181 Accuracy 0.3573\n",
      "Epoch 95 Batch 0 Loss 0.1695 Accuracy 0.3417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 50 Loss 0.1943 Accuracy 0.3618\n",
      "Epoch 95 Batch 100 Loss 0.2111 Accuracy 0.3580\n",
      "Epoch 95 Loss 0.2170 Accuracy 0.3571\n",
      "Epoch 96 Batch 0 Loss 0.1365 Accuracy 0.3615\n",
      "Epoch 96 Batch 50 Loss 0.1955 Accuracy 0.3586\n",
      "Epoch 96 Batch 100 Loss 0.2089 Accuracy 0.3581\n",
      "Epoch 96 Loss 0.2175 Accuracy 0.3569\n",
      "Epoch 97 Batch 0 Loss 0.1883 Accuracy 0.3490\n",
      "Epoch 97 Batch 50 Loss 0.1874 Accuracy 0.3606\n",
      "Epoch 97 Batch 100 Loss 0.2067 Accuracy 0.3580\n",
      "Epoch 97 Loss 0.2158 Accuracy 0.3567\n",
      "Epoch 98 Batch 0 Loss 0.1666 Accuracy 0.3635\n",
      "Epoch 98 Batch 50 Loss 0.1864 Accuracy 0.3588\n",
      "Epoch 98 Batch 100 Loss 0.2053 Accuracy 0.3587\n",
      "Epoch 98 Loss 0.2133 Accuracy 0.3572\n",
      "Epoch 99 Batch 0 Loss 0.1476 Accuracy 0.3656\n",
      "Epoch 99 Batch 50 Loss 0.1817 Accuracy 0.3615\n",
      "Epoch 99 Batch 100 Loss 0.2031 Accuracy 0.3584\n",
      "Epoch 99 Loss 0.2124 Accuracy 0.3569\n",
      "Epoch 100 Batch 0 Loss 0.1844 Accuracy 0.3698\n",
      "Epoch 100 Batch 50 Loss 0.1838 Accuracy 0.3617\n",
      "Epoch 100 Batch 100 Loss 0.2027 Accuracy 0.3592\n",
      "Epoch 100 Loss 0.2117 Accuracy 0.3576\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', 'bonjour', '.']\n"
     ]
    }
   ],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: eat some more of these french  and have some tea\n",
      "Predicted translation: ['<start>', 'fais', 'un', 'fran', 'ais', '.']\n"
     ]
    }
   ],
   "source": [
    "translate(\"eat some more of these french and have some tea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
